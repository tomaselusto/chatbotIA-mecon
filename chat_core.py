from sentence_transformers import SentenceTransformer
import chromadb
import ollama



# Funci贸n para inicializar solo cuando haga falta
def inicializar_embeddings():
    return SentenceTransformer("all-mpnet-base-v2")

def inicializar_chromadb():
    client = chromadb.PersistentClient(path="./chroma_db")
    collection = client.get_or_create_collection(name="chatbot_contexto")
    return collection

modelo_embeddings = inicializar_embeddings()
collection = inicializar_chromadb()
def dividir_texto_overlap(texto, max_length=512, overlap=100):
    palabras = texto.split()
    fragmentos = []
    i = 0
    while i < len(palabras):
        chunk = palabras[i:i + max_length]
        fragmento = " ".join(chunk)
        fragmentos.append(fragmento)
        i += max_length - overlap
    return fragmentos

# Las funciones usan los inicializadores arriba
def buscar_en_chromadb(consulta, top_k=5):
    modelo_embeddings = inicializar_embeddings()
    collection = inicializar_chromadb()
    
    embedding_consulta = modelo_embeddings.encode(consulta).tolist()
    resultados = collection.query(
        query_embeddings=[embedding_consulta],
        n_results=top_k
    )
    
    #para ver qu茅 encuentra
    print(f" Resultados para: {consulta}")
    for doc in resultados["documents"][0]:
        print(f" {doc[:100]}...")

    fragmentos_encontrados = []
    for i in range(len(resultados["documents"][0])):
        fragmentos_encontrados.append({
            "fragmento": resultados["documents"][0][i],
            "titulo": resultados["metadatas"][0][i]["titulo"],
            "url": resultados["metadatas"][0][i]["url"]
        })
    return fragmentos_encontrados
def generar_respuesta(consulta):
    fragmentos = buscar_en_chromadb(consulta)

    if not fragmentos:
        return "No encontr茅 informaci贸n relevante sobre eso."

    contexto = "\n\n".join(["- {}".format(f["fragmento"]) for f in fragmentos])

    #  Debug
    print("------ CONTEXTO ENVIADO A OLLAMA ------")
    print(contexto)
    print("------ FIN CONTEXTO ------")

    prompt = f"""Respond茅 como un asistente del Ministerio de Econom铆a.
Respond茅 solamente con la siguiente informaci贸n. No inventes datos.

{contexto}

Pregunta del usuario: {consulta}

Si no hay informaci贸n suficiente para responder, dec铆: "No tengo informaci贸n sobre eso".
"""

    respuesta = ollama.chat(
        model="llama3.2:1b",
        messages=[{"role": "user", "content": prompt}]
    )
    return respuesta["message"]["content"]




#def generar_respuesta(consulta):
#    fragmentos = buscar_en_chromadb(consulta)
#    if not fragmentos:
#        return "No encontr茅 informaci贸n relevante sobre eso."
#    
#    print("Fragmentos encontrados:")
#    for f in fragmentos:
#        print(f"- {f['fragmento'][:100]}...")
#
#    contexto = "\n\n".join(["- {}".format(f["fragmento"]) for f in fragmentos])
#
#    prompt = f"""Actu谩s como un asistente del Ministerio de Econom铆a.
# Respond茅 solamente con la siguiente informaci贸n:
#{contexto}
#
#Si no hay informaci贸n, dec铆 "No tengo informaci贸n sobre eso".
#
#Pregunta: {consulta}
#"""
#
#    respuesta = ollama.chat(
#        model="llama3.2:1b",
#        messages=[{"role": "user", "content": prompt}]
#    )
#    return respuesta["message"]["content"]
