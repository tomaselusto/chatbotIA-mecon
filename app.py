import streamlit as st
from logger import guardar_interaccion
import json, datetime
from chat_core import dividir_texto_overlap, modelo_embeddings, collection
import os, fitz, docx
from cargarContexto import cargar_contexto_desde_json

st.set_page_config(page_title="Recursos Humanos - Ministerio de Econom√≠a", page_icon="ü§ñ")


# Cargar autom√°ticamente el contexto si la base est√° vac√≠a
if collection.count() == 0:
    st.warning("‚ö†Ô∏è Base vac√≠a. Cargando contexto.json autom√°ticamente...")
    cargados = cargar_contexto_desde_json()
    st.success(f"üìÑ Se cargaron {cargados} fragmentos.")

st.sidebar.markdown("### ‚ÑπÔ∏è Estado de la colecci√≥n")
try:
    from chat_core import collection
    total_docs = collection.count()
    st.sidebar.success(f"üìÑ Fragmentos cargados: {total_docs}")
except Exception as e:
    st.sidebar.error(f"‚ùå Error al consultar ChromaDB: {e}")

modo= st.sidebar.radio("üìã Modo", ["Chat", "Ver Logs"]) #seleccionamos el modo
debug_mode = st.sidebar.checkbox("ü™õ Modo debug", value=False)


# Intentar importar el chatbot
try:
    from chat_core import generar_respuesta
    st.success("‚úÖ Backend cargado correctamente.")
except Exception as e:
    st.error(f"‚ùå Error al cargar el backend: {e}")
    st.stop()

#modo log:
if modo == "Ver Logs":
    st.title("üìä Historial de Interacciones")
    try:
        with open("logs_chat.jsonl", "r", encoding="utf-8") as f:
            lineas = f.readlines()
            if not lineas:
                st.info("A√∫n no hay interacciones guardadas.")
            else:
                for linea in reversed(lineas[-50:]):  # Mostrar los √∫ltimos 50
                    log = json.loads(linea)
                    st.markdown(f"**üïí** {log['timestamp']}")
                    st.markdown(f"**üßë Usuario:** {log['pregunta']}")
                    st.markdown(f"**ü§ñ Chatbot:** {log['respuesta']}")
                    st.markdown(f"**üìå Feedback:** {log.get('resultado', 'sin feedback')}")
                    st.markdown("---")
    except FileNotFoundError:
        st.warning("El archivo de logs a√∫n no existe.")
    st.stop()  # No seguimos con el modo chat   

# Modo Chat
   
st.title("ü§ñ Maranito - Recursos Humanos - Ministerio de Econom√≠a")
st.write("Consult√° sobre la informaci√≥n interna de Recursos Humanos.")
#subida de documentos
st.subheader("üìÅ Subir nuevo documento PDF, DOCX o JSON")
archivo_subido = st.file_uploader("Seleccion√° un archivo JSON v√°lido", type=["json","pdf","docx"]) #Esto te permite subir archivos .json como el original, y el chatbot los va "entrenando" en tiempo real
if archivo_subido is not None:
    try:
        total_fragmentos = 0
        now = datetime.datetime.now().timestamp()

        # JSON
        if archivo_subido.name.endswith(".json"):
            data = json.load(archivo_subido)
            for item in data:
                titulo = item.get("titulo", "Sin t√≠tulo")
                url = item.get("url", "")
                contenido = item.get("contenido", "")
                fragmentos = dividir_texto_overlap(contenido)

                for i, fragmento in enumerate(fragmentos):
                    fragment_id = f"{titulo}_{i}_{now}"
                    embedding = modelo_embeddings.encode(fragmento).tolist()
                    collection.add(
                        ids=[fragment_id],
                        embeddings=[embedding],
                        metadatas=[{"titulo": titulo, "url": url}],
                        documents=[fragmento]
                    )
                    total_fragmentos += 1

        # PDF
        elif archivo_subido.name.endswith(".pdf"):
            pdf = fitz.open(stream=archivo_subido.read(), filetype="pdf")
            texto_pdf = ""
            for page in pdf:
                texto_pdf += page.get_text()
            pdf.close()

            fragmentos = dividir_texto_overlap(texto_pdf)
            for i, fragmento in enumerate(fragmentos):
                fragment_id = f"PDF_{i}_{now}"
                embedding = modelo_embeddings.encode(fragmento).tolist()
                collection.add(
                    ids=[fragment_id],
                    embeddings=[embedding],
                    metadatas=[{"titulo": archivo_subido.name, "url": ""}],
                    documents=[fragmento]
                )
                total_fragmentos += 1

        # DOCX
        elif archivo_subido.name.endswith(".docx"):
            doc = docx.Document(archivo_subido)
            texto_doc = "\n".join([p.text for p in doc.paragraphs])
            fragmentos = dividir_texto_overlap(texto_doc)
            for i, fragmento in enumerate(fragmentos):
                fragment_id = f"DOCX_{i}_{now}"
                embedding = modelo_embeddings.encode(fragmento).tolist()
                collection.add(
                    ids=[fragment_id],
                    embeddings=[embedding],
                    metadatas=[{"titulo": archivo_subido.name, "url": ""}],
                    documents=[fragmento]
                )
                total_fragmentos += 1

        st.success(f"‚úÖ Documento indexado correctamente. Fragmentos a√±adidos: {total_fragmentos}")

    except Exception as e:
        st.error(f"‚ùå Error al procesar el archivo: {e}")
#Interfaz del chatbot
if "historial" not in st.session_state:
    st.session_state.historial = []

consulta = st.text_input("‚úçÔ∏è Escrib√≠ tu consulta:")

if st.button("Enviar") and consulta.strip():
    with st.spinner("ü§ñ Generando respuesta..."):
        try:
            from chat_core import buscar_en_chromadb  # solo para modo debug

            fragmentos = buscar_en_chromadb(consulta, top_k=5)
            if not fragmentos:
                respuesta = "No encontr√© informaci√≥n relevante sobre eso."
            else:
                contexto = "\n\n".join([
                    f"T√≠tulo: {f['titulo']}\nContenido: {f['fragmento']}"
                    for f in fragmentos
                ])
                
                if debug_mode:
                    st.subheader("üß© Fragmentos encontrados")
                    for i, f in enumerate(fragmentos):
                        st.markdown(f"**{i+1}. {f['titulo']}**")
                        st.code(f["fragmento"][:700] + "...")

                    st.subheader("üß† Contexto enviado a Ollama")
                    st.code(contexto[:3000] + "...")

                from chat_core import ollama
                prompt = f"""Sos un asistente del Ministerio de Econom√≠a.
Respond√© solamente con la siguiente informaci√≥n. No inventes datos.

{contexto}

Pregunta del usuario: {consulta}

Si no hay informaci√≥n suficiente para responder, dec√≠: "No tengo informaci√≥n sobre eso".
"""             
                respuesta_obj = ollama.chat(
                    model="llama3.2:1b",
                    messages=[{"role": "user", "content": prompt}]
                )

                respuesta = respuesta_obj["message"]["content"]

            st.session_state.historial.append((consulta, respuesta))
            guardar_interaccion(consulta, respuesta)
        except Exception as e:
            st.error(f"‚ùå Error al generar respuesta: {e}")
            
                
        try:
            respuesta = generar_respuesta(consulta)
            guardar_interaccion(consulta, respuesta)  # Guardar la interacci√≥n en el log
            st.session_state.historial.append((consulta, respuesta)) #feedback sin valor a√∫n
        except Exception as e:
            st.error(f"‚ùå Error al generar respuesta: {e}")
            
#mostrar historial
st.divider()
st.subheader("üí¨ Historial de conversaci√≥n")
for idx, (pregunta, respuesta) in enumerate(reversed(st.session_state.historial)):
    st.markdown(f"üßë **Usuario:** {pregunta}")
    st.markdown(f"ü§ñ **Chatbot:** {respuesta}")

    col1, col2 = st.columns([1, 1])
    with col1:
        if st.button("üëç √ötil", key=f"like_{idx}"):
            guardar_interaccion(pregunta, respuesta, resultado="üëç")
            st.success("¬°Gracias por tu feedback!")
    with col2:
        if st.button("üëé No fue √∫til", key=f"dislike_{idx}"):
            guardar_interaccion(pregunta, respuesta, resultado="üëé")
            st.warning("Gracias, lo tendremos en cuenta.")

    st.markdown("---")

#for pregunta, respuesta in reversed(st.session_state.historial):
#    st.markdown(f"**üßë Usuario:** {pregunta}")
#    st.markdown(f"**ü§ñ Chatbot:** {respuesta}")
#    st.markdown("---")
